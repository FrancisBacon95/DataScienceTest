{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[RandomForest 하이퍼 파라미터 조정(GridSearch)](https://injo.tistory.com/30)\n",
    "\n",
    "[GridSearchCV](https://2-chae.github.io/category/1.ai/29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. GridSearchCV를 통한 랜덤포레스트의 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = { 'n_estimators' : [10, 100],\n",
    "           'max_depth' : [6, 8, 10, 12],\n",
    "           'min_samples_leaf' : [8, 12, 18],\n",
    "           'min_samples_split' : [8, 16, 20]\n",
    "            }\n",
    "\n",
    "# RandomForestClassifier 객체 생성 후 GridSearchCV 수행\n",
    "rf_clf = RandomForestClassifier(random_state = 0, n_jobs = -1)\n",
    "grid_cv = GridSearchCV(rf_clf, param_grid = params, cv = 3, n_jobs = -1)\n",
    "grid_cv.fit(X_train, y_train)\n",
    "\n",
    "print('최적 하이퍼 파라미터: ', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 위의 결과로 나온 최적 하이퍼 파라미터로 다시 모델을 학습하여 \n",
    "\n",
    "   # 테스트 세트 데이터에서 예측 성능을 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf1 = RandomForestClassifier(n_estimators = 100, \n",
    "                                max_depth = 12,\n",
    "                                min_samples_leaf = 8,\n",
    "                                min_samples_split = 8,\n",
    "                                random_state = 0,\n",
    "                                n_jobs = -1)\n",
    "rf_clf1.fit(X_train, y_train)\n",
    "pred = rf_clf1.predict(X_test)\n",
    "print('예측 정확도: {:.4f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Random Forest의 각 피처의 중요도 시각화 : featureimportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "ftr_importances_values = rf_clf1.feature_importances_\n",
    "ftr_importances = pd.Series(ftr_importances_values, index = X_train.columns)\n",
    "ftr_top20 = ftr_importances.sort_values(ascending=False)[:20]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Top 20 Feature Importances')\n",
    "sns.barplot(x=ftr_top20, y=ftr_top20.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(labels, predictions, normalize='true')\n",
    "\n",
    "disp = plot_confusion_matrix(classifier, X_test, y_test,\n",
    "display_labels=class_names, cmap=plt.cm.Blues, normalize='true')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
